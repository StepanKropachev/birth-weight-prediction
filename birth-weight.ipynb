{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mapie -q\n",
    "!pip install catboost optuna -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Get multiple outputs from one cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Train/Test splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# tuning\n",
    "import optuna\n",
    "\n",
    "# Modeling\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from mapie.regression import MapieRegressor\n",
    "\n",
    "\n",
    "# Ignore warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Birth Weight Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "- Upload the data ✅\n",
    "- Descriptive statistics ✅\n",
    "- Resort columns \n",
    "- Cross-features correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "Rows, Columns:\n",
      "--------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(108082, 38)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "Columns' names:\n",
      "---------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['id', 'ATTEND', 'BFACIL', 'BMI', 'CIG_0', 'DLMP_MM', 'DMAR', 'DOB_MM',\n",
       "       'DOB_TT', 'DOB_WK', 'FAGECOMB', 'FEDUC', 'ILLB_R', 'ILOP_R', 'ILP_R',\n",
       "       'LD_INDL', 'MAGER', 'MBSTATE_REC', 'MEDUC', 'M_Ht_In', 'NO_INFEC',\n",
       "       'NO_MMORB', 'NO_RISKS', 'PAY', 'PAY_REC', 'PRECARE', 'PREVIS',\n",
       "       'PRIORDEAD', 'PRIORLIVE', 'PRIORTERM', 'PWgt_R', 'RDMETH_REC',\n",
       "       'RESTATUS', 'RF_CESAR', 'RF_CESARN', 'SEX', 'WTGAIN', 'DBWT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Column / Datatype:\n",
      "-----------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id               int64\n",
       "ATTEND           int64\n",
       "BFACIL           int64\n",
       "BMI            float64\n",
       "CIG_0            int64\n",
       "DLMP_MM          int64\n",
       "DMAR            object\n",
       "DOB_MM           int64\n",
       "DOB_TT           int64\n",
       "DOB_WK           int64\n",
       "FAGECOMB         int64\n",
       "FEDUC            int64\n",
       "ILLB_R           int64\n",
       "ILOP_R           int64\n",
       "ILP_R            int64\n",
       "LD_INDL         object\n",
       "MAGER            int64\n",
       "MBSTATE_REC      int64\n",
       "MEDUC            int64\n",
       "M_Ht_In          int64\n",
       "NO_INFEC         int64\n",
       "NO_MMORB         int64\n",
       "NO_RISKS         int64\n",
       "PAY              int64\n",
       "PAY_REC          int64\n",
       "PRECARE          int64\n",
       "PREVIS           int64\n",
       "PRIORDEAD        int64\n",
       "PRIORLIVE        int64\n",
       "PRIORTERM        int64\n",
       "PWgt_R           int64\n",
       "RDMETH_REC       int64\n",
       "RESTATUS         int64\n",
       "RF_CESAR        object\n",
       "RF_CESARN        int64\n",
       "SEX             object\n",
       "WTGAIN           int64\n",
       "DBWT             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ATTEND</th>\n",
       "      <th>BFACIL</th>\n",
       "      <th>BMI</th>\n",
       "      <th>CIG_0</th>\n",
       "      <th>DLMP_MM</th>\n",
       "      <th>DMAR</th>\n",
       "      <th>DOB_MM</th>\n",
       "      <th>DOB_TT</th>\n",
       "      <th>DOB_WK</th>\n",
       "      <th>...</th>\n",
       "      <th>PRIORLIVE</th>\n",
       "      <th>PRIORTERM</th>\n",
       "      <th>PWgt_R</th>\n",
       "      <th>RDMETH_REC</th>\n",
       "      <th>RESTATUS</th>\n",
       "      <th>RF_CESAR</th>\n",
       "      <th>RF_CESARN</th>\n",
       "      <th>SEX</th>\n",
       "      <th>WTGAIN</th>\n",
       "      <th>DBWT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.5</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>1434</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>24</td>\n",
       "      <td>2800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2156</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27.3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1241</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>135</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>27</td>\n",
       "      <td>2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1649</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>29</td>\n",
       "      <td>3657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23.6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>752</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>37</td>\n",
       "      <td>3742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ATTEND  BFACIL   BMI  CIG_0  DLMP_MM DMAR  DOB_MM  DOB_TT  DOB_WK  ...  \\\n",
       "0   0       1       1  18.5      0       12           10    1434       5  ...   \n",
       "1   1       1       1  18.3      2        4    1      12    2156       6  ...   \n",
       "2   2       1       1  27.3      0        3    2      12    1241       2  ...   \n",
       "3   3       1       1  24.0      0        7    2       4    1649       2  ...   \n",
       "4   4       2       1  23.6      0        6    1       3     752       2  ...   \n",
       "\n",
       "   PRIORLIVE  PRIORTERM  PWgt_R  RDMETH_REC  RESTATUS RF_CESAR  RF_CESARN  \\\n",
       "0          0          0     108           1         1        N          0   \n",
       "1          2          1     100           1         1        N          0   \n",
       "2          2          2     135           4         1        Y          2   \n",
       "3          0          0     111           3         1        N          0   \n",
       "4          2          0     121           4         1        Y          2   \n",
       "\n",
       "   SEX  WTGAIN  DBWT  \n",
       "0    F      24  2800  \n",
       "1    M      18  1900  \n",
       "2    F      27  2960  \n",
       "3    M      29  3657  \n",
       "4    F      37  3742  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Descriptive statistic:\n",
      "---------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ATTEND</th>\n",
       "      <th>BFACIL</th>\n",
       "      <th>BMI</th>\n",
       "      <th>CIG_0</th>\n",
       "      <th>DLMP_MM</th>\n",
       "      <th>DOB_MM</th>\n",
       "      <th>DOB_TT</th>\n",
       "      <th>DOB_WK</th>\n",
       "      <th>FAGECOMB</th>\n",
       "      <th>...</th>\n",
       "      <th>PREVIS</th>\n",
       "      <th>PRIORDEAD</th>\n",
       "      <th>PRIORLIVE</th>\n",
       "      <th>PRIORTERM</th>\n",
       "      <th>PWgt_R</th>\n",
       "      <th>RDMETH_REC</th>\n",
       "      <th>RESTATUS</th>\n",
       "      <th>RF_CESARN</th>\n",
       "      <th>WTGAIN</th>\n",
       "      <th>DBWT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>108082.0</td>\n",
       "      <td>108082.0</td>\n",
       "      <td>108082.0</td>\n",
       "      <td>108082.0</td>\n",
       "      <td>108082.0</td>\n",
       "      <td>108082.0</td>\n",
       "      <td>108082.0</td>\n",
       "      <td>108082.0</td>\n",
       "      <td>108082.0</td>\n",
       "      <td>108082.0</td>\n",
       "      <td>...</td>\n",
       "      <td>108082.0</td>\n",
       "      <td>108082.0</td>\n",
       "      <td>108082.0</td>\n",
       "      <td>108082.0</td>\n",
       "      <td>108082.0</td>\n",
       "      <td>108082.0</td>\n",
       "      <td>108082.0</td>\n",
       "      <td>108082.0</td>\n",
       "      <td>108082.0</td>\n",
       "      <td>108082.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54040.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1233.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>31201.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2965.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>54040.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>81061.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1735.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3629.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>108081.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>6840.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id    ATTEND    BFACIL       BMI     CIG_0   DLMP_MM    DOB_MM  \\\n",
       "count  108082.0  108082.0  108082.0  108082.0  108082.0  108082.0  108082.0   \n",
       "mean    54040.0       1.0       1.0      29.0       2.0      11.0       7.0   \n",
       "std     31201.0       1.0       0.0      13.0       8.0      20.0       3.0   \n",
       "min         0.0       1.0       1.0      13.0       0.0       1.0       1.0   \n",
       "25%     27020.0       1.0       1.0      22.0       0.0       4.0       4.0   \n",
       "50%     54040.0       1.0       1.0      26.0       0.0       7.0       7.0   \n",
       "75%     81061.0       1.0       1.0      31.0       0.0      10.0      10.0   \n",
       "max    108081.0       9.0       9.0     100.0      99.0      99.0      12.0   \n",
       "\n",
       "         DOB_TT    DOB_WK  FAGECOMB  ...    PREVIS  PRIORDEAD  PRIORLIVE  \\\n",
       "count  108082.0  108082.0  108082.0  ...  108082.0   108082.0   108082.0   \n",
       "mean     1233.0       4.0      40.0  ...      14.0        0.0        1.0   \n",
       "std       633.0       2.0      22.0  ...      14.0        5.0        4.0   \n",
       "min         0.0       1.0      14.0  ...       0.0        0.0        0.0   \n",
       "25%       801.0       2.0      28.0  ...       9.0        0.0        0.0   \n",
       "50%      1238.0       4.0      33.0  ...      12.0        0.0        1.0   \n",
       "75%      1735.0       6.0      38.0  ...      14.0        0.0        2.0   \n",
       "max      9999.0       7.0      99.0  ...      99.0       99.0       99.0   \n",
       "\n",
       "       PRIORTERM    PWgt_R  RDMETH_REC  RESTATUS  RF_CESARN    WTGAIN  \\\n",
       "count   108082.0  108082.0    108082.0  108082.0   108082.0  108082.0   \n",
       "mean         1.0     176.0         2.0       1.0        0.0      32.0   \n",
       "std          5.0     125.0         1.0       1.0        2.0      19.0   \n",
       "min          0.0      75.0         1.0       1.0        0.0       0.0   \n",
       "25%          0.0     130.0         1.0       1.0        0.0      20.0   \n",
       "50%          0.0     150.0         1.0       1.0        0.0      30.0   \n",
       "75%          1.0     182.0         3.0       2.0        0.0      40.0   \n",
       "max         99.0     999.0         9.0       4.0       99.0      99.0   \n",
       "\n",
       "           DBWT  \n",
       "count  108082.0  \n",
       "mean     3260.0  \n",
       "std       590.0  \n",
       "min       227.0  \n",
       "25%      2965.0  \n",
       "50%      3300.0  \n",
       "75%      3629.0  \n",
       "max      6840.0  \n",
       "\n",
       "[8 rows x 34 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "The sum of null values:\n",
      "-----------------------\n",
      "id             0\n",
      "ATTEND         0\n",
      "BFACIL         0\n",
      "BMI            0\n",
      "CIG_0          0\n",
      "DLMP_MM        0\n",
      "DMAR           0\n",
      "DOB_MM         0\n",
      "DOB_TT         0\n",
      "DOB_WK         0\n",
      "FAGECOMB       0\n",
      "FEDUC          0\n",
      "ILLB_R         0\n",
      "ILOP_R         0\n",
      "ILP_R          0\n",
      "LD_INDL        0\n",
      "MAGER          0\n",
      "MBSTATE_REC    0\n",
      "MEDUC          0\n",
      "M_Ht_In        0\n",
      "NO_INFEC       0\n",
      "NO_MMORB       0\n",
      "NO_RISKS       0\n",
      "PAY            0\n",
      "PAY_REC        0\n",
      "PRECARE        0\n",
      "PREVIS         0\n",
      "PRIORDEAD      0\n",
      "PRIORLIVE      0\n",
      "PRIORTERM      0\n",
      "PWgt_R         0\n",
      "RDMETH_REC     0\n",
      "RESTATUS       0\n",
      "RF_CESAR       0\n",
      "RF_CESARN      0\n",
      "SEX            0\n",
      "WTGAIN         0\n",
      "DBWT           0\n",
      "dtype: int64\n",
      "-----------------------\n",
      "The sum of NaN values:\n",
      "-----------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "ATTEND         0\n",
       "BFACIL         0\n",
       "BMI            0\n",
       "CIG_0          0\n",
       "DLMP_MM        0\n",
       "DMAR           0\n",
       "DOB_MM         0\n",
       "DOB_TT         0\n",
       "DOB_WK         0\n",
       "FAGECOMB       0\n",
       "FEDUC          0\n",
       "ILLB_R         0\n",
       "ILOP_R         0\n",
       "ILP_R          0\n",
       "LD_INDL        0\n",
       "MAGER          0\n",
       "MBSTATE_REC    0\n",
       "MEDUC          0\n",
       "M_Ht_In        0\n",
       "NO_INFEC       0\n",
       "NO_MMORB       0\n",
       "NO_RISKS       0\n",
       "PAY            0\n",
       "PAY_REC        0\n",
       "PRECARE        0\n",
       "PREVIS         0\n",
       "PRIORDEAD      0\n",
       "PRIORLIVE      0\n",
       "PRIORTERM      0\n",
       "PWgt_R         0\n",
       "RDMETH_REC     0\n",
       "RESTATUS       0\n",
       "RF_CESAR       0\n",
       "RF_CESARN      0\n",
       "SEX            0\n",
       "WTGAIN         0\n",
       "DBWT           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describing the dataset\n",
    "\n",
    "print('--------------')\n",
    "print('Rows, Columns:')\n",
    "print('--------------')\n",
    "df.shape\n",
    "print('---------------')\n",
    "print(\"Columns' names:\")\n",
    "print('---------------')\n",
    "df.columns\n",
    "print('-----------------')\n",
    "print('Column / Datatype:')\n",
    "print('-----------------')\n",
    "df.dtypes\n",
    "print('-----------------')\n",
    "df.head(5)\n",
    "print('---------------------')\n",
    "print('Descriptive statistic:')\n",
    "print('---------------------')\n",
    "round(df.describe())\n",
    "print('-----------------------')\n",
    "print('The sum of null values:')\n",
    "print('-----------------------')\n",
    "print(df.isnull().sum())\n",
    "print('-----------------------')\n",
    "print('The sum of NaN values:')\n",
    "print('-----------------------')\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "- Reduce skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "- Creating new values\n",
    "- One-hot encoding\n",
    "- Dropping the unnecessary\n",
    "- Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset\n",
    "- splitting the train set to validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting df dataset into train and validation\n",
    "# Dropping the categorical data to try the model\n",
    "\n",
    "X = df.drop(['DBWT', 'DMAR', 'LD_INDL', 'RF_CESAR', 'SEX'], axis=1)\n",
    "y = df['DBWT']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Models\n",
    "- Winkler Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Winkler scoring\n",
    "\n",
    "# Notice that we use absolute values due to the possibility of 'quantile crossing' where lower > upper.\n",
    "def WIS_and_coverage(y_true,lower,upper,alpha):\n",
    "\n",
    "    assert np.isnan(y_true) == False, \"y_true contains NaN value(s)\"\n",
    "    assert np.isinf(y_true) == False, \"y_true contains inf values(s)\"\n",
    "    assert np.isnan(lower)  == False, \"lower interval value contains NaN value(s)\"\n",
    "    assert np.isinf(lower)  == False, \"lower interval value contains inf values(s)\"\n",
    "    assert np.isnan(upper)  == False, \"upper interval value contains NaN value(s)\"\n",
    "    assert np.isinf(upper)  == False, \"upper interval value contains inf values(s)\"\n",
    "    assert alpha > 0 and alpha <= 1,  f\"alpha should be (0,1]. Found: {alpha}\"\n",
    "\n",
    "    # WIS for one single row\n",
    "    score = np.abs(upper-lower)\n",
    "    if y_true < np.minimum(upper,lower):\n",
    "        score += ((2/alpha) * (np.minimum(upper,lower) - y_true))\n",
    "    if y_true > np.maximum(upper,lower):\n",
    "        score += ((2/alpha) * (y_true - np.maximum(upper,lower)))\n",
    "    # coverage for one single row\n",
    "    coverage  = 1 # assume is within coverage\n",
    "    if (y_true < np.minimum(upper,lower)) or (y_true > np.maximum(upper,lower)):\n",
    "        coverage = 0\n",
    "    return score, coverage\n",
    "\n",
    "# vectorize the function\n",
    "v_WIS_and_coverage = np.vectorize(WIS_and_coverage)\n",
    "\n",
    "def score(y_true,lower,upper,alpha):\n",
    "    \"\"\"\n",
    "    This is an implementation of the Winkler Interval score (https://otexts.com/fpp3/distaccuracy.html#winkler-score).\n",
    "    The mean over all of the individual Winkler Interval scores (MWIS) is returned, along with the coverage.\n",
    "\n",
    "    See:\n",
    "    [1] Robert L. Winkler \"A Decision-Theoretic Approach to Interval Estimation\", Journal of the American Statistical Association, vol. 67, pp. 187-191 (1972) (https://doi.org/10.1080/01621459.1972.10481224)\n",
    "    [2] Tilmann Gneiting and Adrian E Raftery \"Strictly Proper Scoring Rules, Prediction, and Estimation\", Journal of the American Statistical Association, vol. 102, pp. 359-378 (2007) (https://doi.org/10.1198/016214506000001437) (Section 6.2)\n",
    "\n",
    "    Version: 1.0.4\n",
    "    Author:  Carl McBride Ellis\n",
    "    Date:    2023-12-07\n",
    "    \"\"\"\n",
    "\n",
    "    assert y_true.ndim == 1, \"y_true: pandas Series or 1D array expected\"\n",
    "    assert lower.ndim  == 1, \"lower: pandas Series or 1D array expected\"\n",
    "    assert upper.ndim  == 1, \"upper: pandas Series or 1D array expected\"\n",
    "    assert isinstance(alpha, float) == True, \"alpha: float expected\"\n",
    "\n",
    "    WIS_scores, coverage = v_WIS_and_coverage(y_true,lower,upper,alpha)\n",
    "    MWIS      = np.mean(WIS_scores)\n",
    "    MWIS      = float(MWIS)\n",
    "    coverage  = coverage.sum()/coverage.shape[0]\n",
    "    coverage  = float(coverage)\n",
    "\n",
    "    return MWIS,coverage\n",
    "\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "- Hyperparameter tuning\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "- CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random-forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MWIS score: 4054.473\n",
      "Coverage: 55.9 %\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "predictions = rf_model.predict(X_test)\n",
    "prediction_intervals = np.quantile(predictions, [alpha / 2, 1 - alpha / 2], axis=0)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'y_true': y_test.values,\n",
    "    'lower': prediction_intervals[0],\n",
    "    'upper': prediction_intervals[1]\n",
    "})\n",
    "\n",
    "# MWIS score\n",
    "MWIS, coverage = score(results_df[\"y_true\"], results_df[\"lower\"], results_df[\"upper\"], alpha)\n",
    "\n",
    "# Print MWIS score and coverage\n",
    "print(\"MWIS score:\", round(MWIS, 3))\n",
    "print(\"Coverage:\", round(coverage * 100, 1), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost x Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 18:52:05,187] A new study created in memory with name: no-name-0ea9ae50-51ae-482f-aa3e-3dfd766ab988\n",
      "[I 2024-02-26 18:52:09,813] Trial 0 finished with value: 4718.199490359691 and parameters: {'learning_rate': 0.01684048779008674, 'max_depth': 2, 'subsample': 0.657851577613668, 'colsample_bytree': 0.14886811516954576, 'min_child_weight': 93}. Best is trial 0 with value: 4718.199490359691.\n",
      "[I 2024-02-26 18:52:15,917] Trial 1 finished with value: 4358.019560257299 and parameters: {'learning_rate': 0.008187111814620887, 'max_depth': 4, 'subsample': 0.8481300651129258, 'colsample_bytree': 0.7657722547133762, 'min_child_weight': 99}. Best is trial 1 with value: 4358.019560257299.\n",
      "[I 2024-02-26 18:52:21,982] Trial 2 finished with value: 4200.027789053375 and parameters: {'learning_rate': 0.01268818970883468, 'max_depth': 4, 'subsample': 0.9736776398458722, 'colsample_bytree': 0.337550925424914, 'min_child_weight': 40}. Best is trial 2 with value: 4200.027789053375.\n",
      "[I 2024-02-26 18:52:31,457] Trial 3 finished with value: 6605.869253211813 and parameters: {'learning_rate': 0.0010921314931334283, 'max_depth': 7, 'subsample': 0.21719230220393843, 'colsample_bytree': 0.3400722749720148, 'min_child_weight': 23}. Best is trial 2 with value: 4200.027789053375.\n",
      "[I 2024-02-26 18:52:36,975] Trial 4 finished with value: 3991.398335122893 and parameters: {'learning_rate': 0.026562682154976505, 'max_depth': 3, 'subsample': 0.4708809462779005, 'colsample_bytree': 0.8281879100317331, 'min_child_weight': 70}. Best is trial 4 with value: 3991.398335122893.\n",
      "[I 2024-02-26 18:52:50,968] Trial 5 finished with value: 4749.042150519195 and parameters: {'learning_rate': 0.002726064614854299, 'max_depth': 8, 'subsample': 0.9688456379168806, 'colsample_bytree': 0.6192150277346641, 'min_child_weight': 23}. Best is trial 4 with value: 3991.398335122893.\n",
      "[I 2024-02-26 18:53:04,137] Trial 6 finished with value: 4109.54617397296 and parameters: {'learning_rate': 0.006802801431208769, 'max_depth': 9, 'subsample': 0.2230874986777519, 'colsample_bytree': 0.49307882381631213, 'min_child_weight': 60}. Best is trial 4 with value: 3991.398335122893.\n",
      "[I 2024-02-26 18:53:14,224] Trial 7 finished with value: 3656.1699595266628 and parameters: {'learning_rate': 0.02914542138740083, 'max_depth': 7, 'subsample': 0.06833025560084728, 'colsample_bytree': 0.9886211873931461, 'min_child_weight': 39}. Best is trial 7 with value: 3656.1699595266628.\n",
      "[I 2024-02-26 18:53:33,702] Trial 8 finished with value: 4356.851185669391 and parameters: {'learning_rate': 0.003048504859062625, 'max_depth': 10, 'subsample': 0.9604763521494816, 'colsample_bytree': 0.9409617605883702, 'min_child_weight': 78}. Best is trial 7 with value: 3656.1699595266628.\n",
      "[I 2024-02-26 18:53:42,695] Trial 9 finished with value: 5141.705658519445 and parameters: {'learning_rate': 0.008871268388932546, 'max_depth': 5, 'subsample': 0.5733913441105754, 'colsample_bytree': 0.11329337859621083, 'min_child_weight': 52}. Best is trial 7 with value: 3656.1699595266628.\n",
      "[I 2024-02-26 18:53:51,966] Trial 10 finished with value: 3093.4685597381404 and parameters: {'learning_rate': 0.08725999533654503, 'max_depth': 6, 'subsample': 0.05069796620557862, 'colsample_bytree': 0.6547547554195756, 'min_child_weight': 5}. Best is trial 10 with value: 3093.4685597381404.\n",
      "[I 2024-02-26 18:54:01,196] Trial 11 finished with value: 2992.0412937174005 and parameters: {'learning_rate': 0.09679567963234635, 'max_depth': 6, 'subsample': 0.06131757327143178, 'colsample_bytree': 0.974896864519436, 'min_child_weight': 1}. Best is trial 11 with value: 2992.0412937174005.\n",
      "[I 2024-02-26 18:54:10,475] Trial 12 finished with value: 3003.828828687889 and parameters: {'learning_rate': 0.09805578679476966, 'max_depth': 6, 'subsample': 0.056164054876882905, 'colsample_bytree': 0.6767528907196286, 'min_child_weight': 2}. Best is trial 11 with value: 2992.0412937174005.\n",
      "[I 2024-02-26 18:54:15,110] Trial 13 finished with value: 4059.0522736847915 and parameters: {'learning_rate': 0.09375588050449762, 'max_depth': 1, 'subsample': 0.3143544224974031, 'colsample_bytree': 0.7788071315445655, 'min_child_weight': 1}. Best is trial 11 with value: 2992.0412937174005.\n",
      "[I 2024-02-26 18:54:23,720] Trial 14 finished with value: 3602.638070196036 and parameters: {'learning_rate': 0.047999870516823626, 'max_depth': 6, 'subsample': 0.3457125046996877, 'colsample_bytree': 0.47573564085150644, 'min_child_weight': 21}. Best is trial 11 with value: 2992.0412937174005.\n",
      "[I 2024-02-26 18:54:31,046] Trial 15 finished with value: 3637.9426615689836 and parameters: {'learning_rate': 0.051166007995575816, 'max_depth': 5, 'subsample': 0.1722616538031892, 'colsample_bytree': 0.870604365992082, 'min_child_weight': 12}. Best is trial 11 with value: 2992.0412937174005.\n",
      "[I 2024-02-26 18:54:42,734] Trial 16 finished with value: 3436.696095204656 and parameters: {'learning_rate': 0.05327463797545201, 'max_depth': 8, 'subsample': 0.40943012633478926, 'colsample_bytree': 0.6876415468820337, 'min_child_weight': 14}. Best is trial 11 with value: 2992.0412937174005.\n",
      "[I 2024-02-26 18:54:51,604] Trial 17 finished with value: 3767.7532756360197 and parameters: {'learning_rate': 0.02871616351502501, 'max_depth': 7, 'subsample': 0.16871913814876688, 'colsample_bytree': 0.36675521515413817, 'min_child_weight': 34}. Best is trial 11 with value: 2992.0412937174005.\n",
      "[I 2024-02-26 18:54:57,169] Trial 18 finished with value: 3748.730086968137 and parameters: {'learning_rate': 0.08736920405513356, 'max_depth': 3, 'subsample': 0.10866935161582757, 'colsample_bytree': 0.5797954516875148, 'min_child_weight': 2}. Best is trial 11 with value: 2992.0412937174005.\n",
      "[I 2024-02-26 18:55:04,119] Trial 19 finished with value: 3643.844626925297 and parameters: {'learning_rate': 0.05358075083331976, 'max_depth': 4, 'subsample': 0.7330567800961342, 'colsample_bytree': 0.9032934236263876, 'min_child_weight': 28}. Best is trial 11 with value: 2992.0412937174005.\n",
      "[I 2024-02-26 18:55:19,585] Trial 20 finished with value: 3654.8651388216776 and parameters: {'learning_rate': 0.01765294456238461, 'max_depth': 10, 'subsample': 0.29471818058875726, 'colsample_bytree': 0.7242974407800977, 'min_child_weight': 15}. Best is trial 11 with value: 2992.0412937174005.\n",
      "[I 2024-02-26 18:55:27,000] Trial 21 finished with value: 3010.9981496473947 and parameters: {'learning_rate': 0.09946498853850373, 'max_depth': 6, 'subsample': 0.05236521557223313, 'colsample_bytree': 0.6447436582304134, 'min_child_weight': 8}. Best is trial 11 with value: 2992.0412937174005.\n",
      "[I 2024-02-26 18:55:34,887] Trial 22 finished with value: 3456.0189276646233 and parameters: {'learning_rate': 0.0682126851578293, 'max_depth': 6, 'subsample': 0.12987225682120412, 'colsample_bytree': 0.5380047362285834, 'min_child_weight': 10}. Best is trial 11 with value: 2992.0412937174005.\n",
      "[I 2024-02-26 18:55:45,500] Trial 23 finished with value: 3457.8427823867996 and parameters: {'learning_rate': 0.03649815667093518, 'max_depth': 8, 'subsample': 0.05223260951092146, 'colsample_bytree': 0.43798608320141275, 'min_child_weight': 1}. Best is trial 11 with value: 2992.0412937174005.\n",
      "[I 2024-02-26 18:55:53,727] Trial 24 finished with value: 3458.9263798208754 and parameters: {'learning_rate': 0.09851418483183419, 'max_depth': 5, 'subsample': 0.2604140785858155, 'colsample_bytree': 0.8194669396420939, 'min_child_weight': 10}. Best is trial 11 with value: 2992.0412937174005.\n",
      "[I 2024-02-26 18:56:02,348] Trial 25 finished with value: 3706.8681216673917 and parameters: {'learning_rate': 0.06148422398806557, 'max_depth': 6, 'subsample': 0.3929301896460432, 'colsample_bytree': 0.2138154365768209, 'min_child_weight': 32}. Best is trial 11 with value: 2992.0412937174005.\n",
      "[I 2024-02-26 18:56:14,676] Trial 26 finished with value: 3580.516366050428 and parameters: {'learning_rate': 0.03936209128360881, 'max_depth': 7, 'subsample': 0.14289004348680592, 'colsample_bytree': 0.5883098609222746, 'min_child_weight': 19}. Best is trial 11 with value: 2992.0412937174005.\n",
      "[I 2024-02-26 18:56:25,789] Trial 27 finished with value: 3528.8204513993796 and parameters: {'learning_rate': 0.07056051748460287, 'max_depth': 5, 'subsample': 0.20386372954684195, 'colsample_bytree': 0.9881104952308927, 'min_child_weight': 46}. Best is trial 11 with value: 2992.0412937174005.\n",
      "[I 2024-02-26 18:56:43,833] Trial 28 finished with value: 3606.308504830725 and parameters: {'learning_rate': 0.023790555094646167, 'max_depth': 9, 'subsample': 0.11142749889857051, 'colsample_bytree': 0.7121520772152765, 'min_child_weight': 7}. Best is trial 11 with value: 2992.0412937174005.\n",
      "[I 2024-02-26 18:56:51,900] Trial 29 finished with value: 4328.565434783316 and parameters: {'learning_rate': 0.01694502070478817, 'max_depth': 3, 'subsample': 0.5664470854120522, 'colsample_bytree': 0.19455623640111158, 'min_child_weight': 86}. Best is trial 11 with value: 2992.0412937174005.\n",
      "[I 2024-02-26 18:57:01,003] Trial 30 finished with value: 4688.165022363313 and parameters: {'learning_rate': 0.004236590844884962, 'max_depth': 6, 'subsample': 0.2642764257749981, 'colsample_bytree': 0.4185559736650054, 'min_child_weight': 17}. Best is trial 11 with value: 2992.0412937174005.\n",
      "[I 2024-02-26 18:57:09,220] Trial 31 finished with value: 3246.1429895872793 and parameters: {'learning_rate': 0.07620165198842949, 'max_depth': 6, 'subsample': 0.07577418597584963, 'colsample_bytree': 0.620872765460765, 'min_child_weight': 6}. Best is trial 11 with value: 2992.0412937174005.\n",
      "[I 2024-02-26 18:57:18,270] Trial 32 finished with value: 2873.510286486945 and parameters: {'learning_rate': 0.09748378118860938, 'max_depth': 7, 'subsample': 0.059633440138433934, 'colsample_bytree': 0.6937922593276811, 'min_child_weight': 6}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 18:57:28,632] Trial 33 finished with value: 3542.2473845589916 and parameters: {'learning_rate': 0.039320256337640185, 'max_depth': 7, 'subsample': 0.699832115952258, 'colsample_bytree': 0.7740754637704645, 'min_child_weight': 9}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 18:57:35,570] Trial 34 finished with value: 3600.925228952564 and parameters: {'learning_rate': 0.09679094200396006, 'max_depth': 4, 'subsample': 0.1613557904638372, 'colsample_bytree': 0.5318389386213238, 'min_child_weight': 30}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 18:57:45,473] Trial 35 finished with value: 3251.258135910377 and parameters: {'learning_rate': 0.06630968743038415, 'max_depth': 8, 'subsample': 0.10879471646132835, 'colsample_bytree': 0.6747706513961109, 'min_child_weight': 25}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 18:57:56,809] Trial 36 finished with value: 5714.948946442343 and parameters: {'learning_rate': 0.001311958479623658, 'max_depth': 7, 'subsample': 0.23228701517890143, 'colsample_bytree': 0.7509580252586827, 'min_child_weight': 16}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 18:58:03,382] Trial 37 finished with value: 3662.4494235877905 and parameters: {'learning_rate': 0.041789442231304985, 'max_depth': 4, 'subsample': 0.8049760797651575, 'colsample_bytree': 0.8327504300939101, 'min_child_weight': 1}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 18:58:14,776] Trial 38 finished with value: 3320.117030392565 and parameters: {'learning_rate': 0.07290194790773157, 'max_depth': 9, 'subsample': 0.4560285400214501, 'colsample_bytree': 0.8864673727968772, 'min_child_weight': 99}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 18:58:21,754] Trial 39 finished with value: 3899.1330642843486 and parameters: {'learning_rate': 0.02080321351465922, 'max_depth': 5, 'subsample': 0.1811714394864511, 'colsample_bytree': 0.6316731837212878, 'min_child_weight': 63}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 18:58:30,450] Trial 40 finished with value: 3429.4429616167617 and parameters: {'learning_rate': 0.06107810609058273, 'max_depth': 8, 'subsample': 0.10141066417604488, 'colsample_bytree': 0.2843870136091333, 'min_child_weight': 37}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 18:58:37,996] Trial 41 finished with value: 3122.370330685467 and parameters: {'learning_rate': 0.08362254998880037, 'max_depth': 6, 'subsample': 0.05022777047504163, 'colsample_bytree': 0.6617533317316792, 'min_child_weight': 6}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 18:58:46,279] Trial 42 finished with value: 3999.4232644884696 and parameters: {'learning_rate': 0.01265757735360233, 'max_depth': 6, 'subsample': 0.051916531414472666, 'colsample_bytree': 0.5712373070292587, 'min_child_weight': 5}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 18:58:54,939] Trial 43 finished with value: 3215.335313888247 and parameters: {'learning_rate': 0.0813770390920256, 'max_depth': 7, 'subsample': 0.10395663150500298, 'colsample_bytree': 0.6559364183315359, 'min_child_weight': 22}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 18:59:02,236] Trial 44 finished with value: 4307.765135042731 and parameters: {'learning_rate': 0.006203431733768684, 'max_depth': 5, 'subsample': 0.21346627865724332, 'colsample_bytree': 0.8009941546935351, 'min_child_weight': 13}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 18:59:11,363] Trial 45 finished with value: 3081.366191868848 and parameters: {'learning_rate': 0.09845553312034307, 'max_depth': 7, 'subsample': 0.1434594118062186, 'colsample_bytree': 0.7163253046170323, 'min_child_weight': 4}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 18:59:21,654] Trial 46 finished with value: 3629.4404390908157 and parameters: {'learning_rate': 0.0314276036687467, 'max_depth': 7, 'subsample': 0.13669800559411488, 'colsample_bytree': 0.7382558097699412, 'min_child_weight': 10}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 18:59:31,712] Trial 47 finished with value: 3390.403031757412 and parameters: {'learning_rate': 0.049614426360106094, 'max_depth': 8, 'subsample': 0.09089173534345707, 'colsample_bytree': 0.9417547173933111, 'min_child_weight': 26}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 18:59:44,838] Trial 48 finished with value: 3363.856749096306 and parameters: {'learning_rate': 0.05959650209588649, 'max_depth': 7, 'subsample': 0.17606529334097043, 'colsample_bytree': 0.8516334185867931, 'min_child_weight': 4}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 18:59:51,241] Trial 49 finished with value: 4223.269489512197 and parameters: {'learning_rate': 0.09710981322787457, 'max_depth': 1, 'subsample': 0.9172988475402466, 'colsample_bytree': 0.5026444620696329, 'min_child_weight': 19}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:00:02,534] Trial 50 finished with value: 3461.9977504819344 and parameters: {'learning_rate': 0.045695180144310184, 'max_depth': 9, 'subsample': 0.3244577194557424, 'colsample_bytree': 0.7119655350871289, 'min_child_weight': 48}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:00:10,661] Trial 51 finished with value: 3216.013345254892 and parameters: {'learning_rate': 0.08208583417887215, 'max_depth': 6, 'subsample': 0.06640976292609123, 'colsample_bytree': 0.5993011689756216, 'min_child_weight': 6}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:00:18,768] Trial 52 finished with value: 3250.9608220377586 and parameters: {'learning_rate': 0.09962551293887269, 'max_depth': 6, 'subsample': 0.1389788137304282, 'colsample_bytree': 0.6387619307778755, 'min_child_weight': 13}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:00:26,022] Trial 53 finished with value: 3571.2638377216676 and parameters: {'learning_rate': 0.057525616583776085, 'max_depth': 5, 'subsample': 0.08000876198289786, 'colsample_bytree': 0.6885008298781395, 'min_child_weight': 2}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:00:36,003] Trial 54 finished with value: 3373.774250375229 and parameters: {'learning_rate': 0.07441905688405374, 'max_depth': 7, 'subsample': 0.2569161736736604, 'colsample_bytree': 0.5613790326207412, 'min_child_weight': 9}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:00:44,663] Trial 55 finished with value: 3787.808178045726 and parameters: {'learning_rate': 0.08357349490321223, 'max_depth': 7, 'subsample': 0.14956248960725166, 'colsample_bytree': 0.061137508908461424, 'min_child_weight': 1}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:00:52,069] Trial 56 finished with value: 3604.2170760290296 and parameters: {'learning_rate': 0.061687269944732344, 'max_depth': 5, 'subsample': 0.08819179417129458, 'colsample_bytree': 0.4784215617396621, 'min_child_weight': 13}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:00:59,796] Trial 57 finished with value: 3732.2633179416803 and parameters: {'learning_rate': 0.04972035380951352, 'max_depth': 4, 'subsample': 0.20308011152016903, 'colsample_bytree': 0.7945886583687982, 'min_child_weight': 18}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:01:07,840] Trial 58 finished with value: 3643.5685509243654 and parameters: {'learning_rate': 0.03371295098000958, 'max_depth': 6, 'subsample': 0.12446553933682215, 'colsample_bytree': 0.9281586678102542, 'min_child_weight': 5}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:01:16,887] Trial 59 finished with value: 5138.082562766627 and parameters: {'learning_rate': 0.0020340025615369064, 'max_depth': 8, 'subsample': 0.05398290668626669, 'colsample_bytree': 0.6980059823272081, 'min_child_weight': 78}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:01:24,854] Trial 60 finished with value: 3455.435588764142 and parameters: {'learning_rate': 0.06961343749942978, 'max_depth': 6, 'subsample': 0.17986580689767348, 'colsample_bytree': 0.7484356499796205, 'min_child_weight': 9}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:01:32,338] Trial 61 finished with value: 3132.7686778454167 and parameters: {'learning_rate': 0.08761176567516571, 'max_depth': 6, 'subsample': 0.061604538243623844, 'colsample_bytree': 0.6617202707824351, 'min_child_weight': 5}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:01:40,116] Trial 62 finished with value: 3119.7857073525397 and parameters: {'learning_rate': 0.08510799850665192, 'max_depth': 6, 'subsample': 0.0500385174237946, 'colsample_bytree': 0.6042103531929893, 'min_child_weight': 7}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:01:49,276] Trial 63 finished with value: 3102.30496624519 and parameters: {'learning_rate': 0.09930555650893848, 'max_depth': 7, 'subsample': 0.11849089208060481, 'colsample_bytree': 0.6051406877121007, 'min_child_weight': 10}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:01:57,836] Trial 64 finished with value: 3142.428390641986 and parameters: {'learning_rate': 0.09865817279105547, 'max_depth': 7, 'subsample': 0.1278629516968368, 'colsample_bytree': 0.5395475098542464, 'min_child_weight': 12}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:02:06,128] Trial 65 finished with value: 3259.360682110633 and parameters: {'learning_rate': 0.07316829676609862, 'max_depth': 7, 'subsample': 0.09076170571147033, 'colsample_bytree': 0.6267438896702087, 'min_child_weight': 16}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:02:16,033] Trial 66 finished with value: 3313.8370628101757 and parameters: {'learning_rate': 0.06630773532711441, 'max_depth': 8, 'subsample': 0.2355980645734014, 'colsample_bytree': 0.7252086826462828, 'min_child_weight': 21}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:02:24,185] Trial 67 finished with value: 3658.9857032347772 and parameters: {'learning_rate': 0.04387832406146113, 'max_depth': 6, 'subsample': 0.36965623582192897, 'colsample_bytree': 0.3953202569228641, 'min_child_weight': 1}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:02:32,767] Trial 68 finished with value: 3454.868720534167 and parameters: {'learning_rate': 0.05415710504375472, 'max_depth': 7, 'subsample': 0.15635284272371505, 'colsample_bytree': 0.443546365797436, 'min_child_weight': 11}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:02:40,044] Trial 69 finished with value: 3519.6938511867284 and parameters: {'learning_rate': 0.08583234314621674, 'max_depth': 5, 'subsample': 0.2947226039857156, 'colsample_bytree': 0.5613109343251721, 'min_child_weight': 58}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:02:54,739] Trial 70 finished with value: 3266.9816837248504 and parameters: {'learning_rate': 0.0987196422441895, 'max_depth': 8, 'subsample': 0.582853145874851, 'colsample_bytree': 0.7657101876556918, 'min_child_weight': 4}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:03:03,486] Trial 71 finished with value: 3302.385334431885 and parameters: {'learning_rate': 0.07433034822509291, 'max_depth': 6, 'subsample': 0.08019278712930956, 'colsample_bytree': 0.6097851773153601, 'min_child_weight': 8}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:03:12,632] Trial 72 finished with value: 3160.757804415813 and parameters: {'learning_rate': 0.0853354508673635, 'max_depth': 7, 'subsample': 0.11220250757273134, 'colsample_bytree': 0.508400539974439, 'min_child_weight': 7}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:03:20,878] Trial 73 finished with value: 3491.4590450956193 and parameters: {'learning_rate': 0.06478268783521014, 'max_depth': 6, 'subsample': 0.19210215133774922, 'colsample_bytree': 0.5928977043196171, 'min_child_weight': 3}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:03:27,875] Trial 74 finished with value: 3460.5926591498273 and parameters: {'learning_rate': 0.08868582825984882, 'max_depth': 5, 'subsample': 0.12031029766287168, 'colsample_bytree': 0.6773521889103351, 'min_child_weight': 15}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:03:35,726] Trial 75 finished with value: 3276.031700295286 and parameters: {'learning_rate': 0.08074636927502721, 'max_depth': 6, 'subsample': 0.08352824911186874, 'colsample_bytree': 0.7031635821411947, 'min_child_weight': 8}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:03:41,141] Trial 76 finished with value: 3974.318824503718 and parameters: {'learning_rate': 0.057202628595829745, 'max_depth': 2, 'subsample': 0.16277922959691388, 'colsample_bytree': 0.6535723193302945, 'min_child_weight': 11}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:03:51,651] Trial 77 finished with value: 3025.703027851975 and parameters: {'learning_rate': 0.07624307213120288, 'max_depth': 7, 'subsample': 0.05269689540406047, 'colsample_bytree': 0.618751889885841, 'min_child_weight': 3}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:04:02,780] Trial 78 finished with value: 3271.728208425913 and parameters: {'learning_rate': 0.06896370062294137, 'max_depth': 7, 'subsample': 0.1049217854730998, 'colsample_bytree': 0.5456898370538508, 'min_child_weight': 3}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:04:16,362] Trial 79 finished with value: 3062.707009988069 and parameters: {'learning_rate': 0.09979370131670336, 'max_depth': 7, 'subsample': 0.14644243931690198, 'colsample_bytree': 0.9996574888110724, 'min_child_weight': 1}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:04:27,260] Trial 80 finished with value: 3247.378536134754 and parameters: {'learning_rate': 0.0759520636082257, 'max_depth': 8, 'subsample': 0.15091863855489562, 'colsample_bytree': 0.9880621559574267, 'min_child_weight': 43}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:04:39,095] Trial 81 finished with value: 2886.7371100097193 and parameters: {'learning_rate': 0.09966290841383493, 'max_depth': 7, 'subsample': 0.08008984570259303, 'colsample_bytree': 0.9087659041412001, 'min_child_weight': 1}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:04:51,683] Trial 82 finished with value: 2968.0729907058285 and parameters: {'learning_rate': 0.08954884162474336, 'max_depth': 7, 'subsample': 0.07695956644205523, 'colsample_bytree': 0.9652899297688423, 'min_child_weight': 1}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:05:03,047] Trial 83 finished with value: 2979.9162493029394 and parameters: {'learning_rate': 0.08841513969385109, 'max_depth': 7, 'subsample': 0.08630132969869013, 'colsample_bytree': 0.9493136090017646, 'min_child_weight': 3}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:05:18,246] Trial 84 finished with value: 2902.6653094456724 and parameters: {'learning_rate': 0.07667463347584588, 'max_depth': 8, 'subsample': 0.07084157853550883, 'colsample_bytree': 0.9664548602281325, 'min_child_weight': 1}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:05:33,785] Trial 85 finished with value: 3823.5576755205866 and parameters: {'learning_rate': 0.01180095191590865, 'max_depth': 9, 'subsample': 0.09627003933201501, 'colsample_bytree': 0.9592665429572285, 'min_child_weight': 3}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:05:47,394] Trial 86 finished with value: 3013.1189254736037 and parameters: {'learning_rate': 0.06443270539401819, 'max_depth': 8, 'subsample': 0.06000231081775354, 'colsample_bytree': 0.8976580705828985, 'min_child_weight': 1}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:06:00,599] Trial 87 finished with value: 3229.913225288636 and parameters: {'learning_rate': 0.05334359739209273, 'max_depth': 8, 'subsample': 0.07514575551753398, 'colsample_bytree': 0.9098715553978916, 'min_child_weight': 7}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:06:13,732] Trial 88 finished with value: 3055.5350772083843 and parameters: {'learning_rate': 0.06384190901409621, 'max_depth': 8, 'subsample': 0.07474547041024583, 'colsample_bytree': 0.9632274161673869, 'min_child_weight': 1}. Best is trial 32 with value: 2873.510286486945.\n",
      "[I 2024-02-26 19:06:27,673] Trial 89 finished with value: 2826.9211152332905 and parameters: {'learning_rate': 0.08871969221743349, 'max_depth': 9, 'subsample': 0.1027419289164267, 'colsample_bytree': 0.864777676719895, 'min_child_weight': 5}. Best is trial 89 with value: 2826.9211152332905.\n",
      "[I 2024-02-26 19:06:41,091] Trial 90 finished with value: 2841.20689181303 and parameters: {'learning_rate': 0.089777540365391, 'max_depth': 10, 'subsample': 0.10149530314917168, 'colsample_bytree': 0.8676314910839406, 'min_child_weight': 14}. Best is trial 89 with value: 2826.9211152332905.\n",
      "[I 2024-02-26 19:06:59,030] Trial 91 finished with value: 2758.543681057407 and parameters: {'learning_rate': 0.09185805664059714, 'max_depth': 10, 'subsample': 0.10627511169638384, 'colsample_bytree': 0.8679770086150229, 'min_child_weight': 5}. Best is trial 91 with value: 2758.543681057407.\n",
      "[I 2024-02-26 19:07:14,821] Trial 92 finished with value: 2770.263103888053 and parameters: {'learning_rate': 0.08886452986194886, 'max_depth': 10, 'subsample': 0.10273244050374793, 'colsample_bytree': 0.857852264708526, 'min_child_weight': 5}. Best is trial 91 with value: 2758.543681057407.\n",
      "[I 2024-02-26 19:07:32,015] Trial 93 finished with value: 2860.9547767355048 and parameters: {'learning_rate': 0.07844214430854489, 'max_depth': 10, 'subsample': 0.10274770767787159, 'colsample_bytree': 0.865059241325322, 'min_child_weight': 6}. Best is trial 91 with value: 2758.543681057407.\n",
      "[I 2024-02-26 19:07:48,163] Trial 94 finished with value: 3952.475279890393 and parameters: {'learning_rate': 0.006776370838495599, 'max_depth': 10, 'subsample': 0.1743126744693762, 'colsample_bytree': 0.8651863376504253, 'min_child_weight': 14}. Best is trial 91 with value: 2758.543681057407.\n",
      "[I 2024-02-26 19:08:07,668] Trial 95 finished with value: 2845.2724602282406 and parameters: {'learning_rate': 0.08827410851152784, 'max_depth': 10, 'subsample': 0.12683883213848027, 'colsample_bytree': 0.8289888317317515, 'min_child_weight': 5}. Best is trial 91 with value: 2758.543681057407.\n",
      "[I 2024-02-26 19:08:33,191] Trial 96 finished with value: 3057.5305334144564 and parameters: {'learning_rate': 0.07686306481043315, 'max_depth': 10, 'subsample': 0.21946386823849334, 'colsample_bytree': 0.8344152915631329, 'min_child_weight': 6}. Best is trial 91 with value: 2758.543681057407.\n",
      "[I 2024-02-26 19:08:52,908] Trial 97 finished with value: 2988.5157194036015 and parameters: {'learning_rate': 0.07048442946798757, 'max_depth': 10, 'subsample': 0.11878791907374667, 'colsample_bytree': 0.9236550840655537, 'min_child_weight': 10}. Best is trial 91 with value: 2758.543681057407.\n",
      "[I 2024-02-26 19:09:12,507] Trial 98 finished with value: 2888.8526866310904 and parameters: {'learning_rate': 0.08981328641372464, 'max_depth': 9, 'subsample': 0.13453658799140228, 'colsample_bytree': 0.8796806677535787, 'min_child_weight': 5}. Best is trial 91 with value: 2758.543681057407.\n",
      "[I 2024-02-26 19:09:36,049] Trial 99 finished with value: 4095.0468111374116 and parameters: {'learning_rate': 0.005173219137524782, 'max_depth': 9, 'subsample': 0.19788642665977021, 'colsample_bytree': 0.8822928117324578, 'min_child_weight': 12}. Best is trial 91 with value: 2758.543681057407.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost parameters: {'learning_rate': 0.09185805664059714, 'max_depth': 10, 'subsample': 0.10627511169638384, 'colsample_bytree': 0.8679770086150229, 'min_child_weight': 5}\n",
      "Best XGBoost MWIS score: 2758.544\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest XGBoost MWIS score:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mround\u001b[39m(best_score_xgboost, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Train the XGBoost model with the best parameters found\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241m.\u001b[39mXGBRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbest_params_xgboost, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     38\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     39\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "# def objective(trial):\n",
    "#     params = {\n",
    "#         \"n_estimators\": 1000,\n",
    "#         \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "#         \"max_depth\": trial.suggest_int(\"max_depth\", 1, 10),\n",
    "#         \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "#         \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "#         \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 100),\n",
    "#     }\n",
    "\n",
    "#     model = XGBRegressor(**params, silent=True)\n",
    "#     model.fit(X_train, y_train)\n",
    "#     predictions = model.predict(X_test)\n",
    "#     prediction_intervals = np.quantile(predictions, [alpha / 2, 1 - alpha / 2], axis=0)\n",
    "#     results_df = pd.DataFrame({\n",
    "#         'y_true': y_test.values,\n",
    "#         'lower': prediction_intervals[0],\n",
    "#         'upper': prediction_intervals[1]\n",
    "#     })\n",
    "#     MWIS, coverage = score(results_df[\"y_true\"], results_df[\"lower\"], results_df[\"upper\"], alpha)\n",
    "#     return MWIS\n",
    "\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective, n_trials=100)\n",
    "\n",
    "# # Retrieve the best parameters and best value from the study\n",
    "# best_params_xgboost = study.best_params\n",
    "# best_score_xgboost = study.best_value\n",
    "\n",
    "# print(\"Best XGBoost parameters:\", best_params_xgboost)\n",
    "# print(\"Best XGBoost MWIS score:\", round(best_score_xgboost, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8679770086150229, device=None,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.09185805664059714, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8679770086150229, device=None,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.09185805664059714, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8679770086150229, device=None,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.09185805664059714, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MWIS score: 3527.016\n",
      "Coverage: 64.8 %\n"
     ]
    }
   ],
   "source": [
    "# Train the XGBoost model with the best parameters found\n",
    "model = XGBRegressor(learning_rate=0.09185805664059714, \n",
    "                     max_depth=10, \n",
    "                     subsample=0.10627511169638384, \n",
    "                     colsample_bytree=0.8679770086150229, \n",
    "                     min_child_weight=5)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "prediction_intervals = np.quantile(predictions, [alpha / 2, 1 - alpha / 2], axis=0)\n",
    "results_df = pd.DataFrame({\n",
    "    'y_true': y_test.values,\n",
    "    'lower': prediction_intervals[0],\n",
    "    'upper': prediction_intervals[1]\n",
    "})\n",
    "MWIS, coverage = score(results_df[\"y_true\"], results_df[\"lower\"], results_df[\"upper\"], alpha)\n",
    "print(\"MWIS score:\", round(MWIS, 3))\n",
    "print(\"Coverage:\", round(coverage * 100, 1), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost x Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 17:49:09,311] A new study created in memory with name: no-name-57e30bf1-e40f-45f5-8b84-03897df87208\n",
      "[I 2024-02-26 17:49:30,052] Trial 0 finished with value: 4596.503531686753 and parameters: {'learning_rate': 0.004761640779102068, 'depth': 8, 'subsample': 0.38100433240553305, 'colsample_bylevel': 0.7802960890718474, 'min_data_in_leaf': 39}. Best is trial 0 with value: 4596.503531686753.\n",
      "[I 2024-02-26 17:49:37,267] Trial 1 finished with value: 3738.5075823514508 and parameters: {'learning_rate': 0.06957916159300247, 'depth': 3, 'subsample': 0.5073122204789776, 'colsample_bylevel': 0.9262351283511784, 'min_data_in_leaf': 63}. Best is trial 1 with value: 3738.5075823514508.\n",
      "[I 2024-02-26 17:49:41,659] Trial 2 finished with value: 6885.065163114176 and parameters: {'learning_rate': 0.002948254263246553, 'depth': 1, 'subsample': 0.16491563824985017, 'colsample_bylevel': 0.36639558292577845, 'min_data_in_leaf': 71}. Best is trial 1 with value: 3738.5075823514508.\n",
      "[I 2024-02-26 17:49:46,113] Trial 3 finished with value: 6824.852463255259 and parameters: {'learning_rate': 0.0029566870634739843, 'depth': 1, 'subsample': 0.13724771950268688, 'colsample_bylevel': 0.986259542721766, 'min_data_in_leaf': 22}. Best is trial 1 with value: 3738.5075823514508.\n",
      "[I 2024-02-26 17:50:20,311] Trial 4 finished with value: 3513.353022288342 and parameters: {'learning_rate': 0.08889944778098616, 'depth': 10, 'subsample': 0.6884370739451692, 'colsample_bylevel': 0.4903479436170228, 'min_data_in_leaf': 77}. Best is trial 4 with value: 3513.353022288342.\n",
      "[I 2024-02-26 17:50:29,847] Trial 5 finished with value: 3948.5412103861986 and parameters: {'learning_rate': 0.029803017676242133, 'depth': 6, 'subsample': 0.5156525535447289, 'colsample_bylevel': 0.19015292250435206, 'min_data_in_leaf': 25}. Best is trial 4 with value: 3513.353022288342.\n",
      "[I 2024-02-26 17:50:43,745] Trial 6 finished with value: 5134.7096621870505 and parameters: {'learning_rate': 0.0030690517119615593, 'depth': 6, 'subsample': 0.7207825531527332, 'colsample_bylevel': 0.7971804527380485, 'min_data_in_leaf': 25}. Best is trial 4 with value: 3513.353022288342.\n",
      "[I 2024-02-26 17:50:56,095] Trial 7 finished with value: 5179.658124060705 and parameters: {'learning_rate': 0.002960875350850508, 'depth': 6, 'subsample': 0.4857112436333124, 'colsample_bylevel': 0.6088480390062646, 'min_data_in_leaf': 37}. Best is trial 4 with value: 3513.353022288342.\n",
      "[I 2024-02-26 17:51:10,438] Trial 8 finished with value: 4309.870689771595 and parameters: {'learning_rate': 0.010842775035945513, 'depth': 9, 'subsample': 0.850065114113369, 'colsample_bylevel': 0.09888600562921906, 'min_data_in_leaf': 70}. Best is trial 4 with value: 3513.353022288342.\n",
      "[I 2024-02-26 17:51:16,056] Trial 9 finished with value: 6492.7866366988865 and parameters: {'learning_rate': 0.004170340630112334, 'depth': 1, 'subsample': 0.6742151351255491, 'colsample_bylevel': 0.7843998267049456, 'min_data_in_leaf': 51}. Best is trial 4 with value: 3513.353022288342.\n",
      "[I 2024-02-26 17:51:51,852] Trial 10 finished with value: 3504.632616407561 and parameters: {'learning_rate': 0.08071414046371626, 'depth': 10, 'subsample': 0.9693813916953271, 'colsample_bylevel': 0.48900366215725455, 'min_data_in_leaf': 99}. Best is trial 10 with value: 3504.632616407561.\n",
      "[I 2024-02-26 17:52:25,576] Trial 11 finished with value: 3491.3904832966023 and parameters: {'learning_rate': 0.09647429934765352, 'depth': 10, 'subsample': 0.9805335986079416, 'colsample_bylevel': 0.436320926351772, 'min_data_in_leaf': 100}. Best is trial 11 with value: 3491.3904832966023.\n",
      "[I 2024-02-26 17:52:44,851] Trial 12 finished with value: 3687.659797763543 and parameters: {'learning_rate': 0.03367126645452604, 'depth': 8, 'subsample': 0.9986319748031454, 'colsample_bylevel': 0.3390414353275871, 'min_data_in_leaf': 99}. Best is trial 11 with value: 3491.3904832966023.\n",
      "[I 2024-02-26 17:53:24,163] Trial 13 finished with value: 3638.092411634229 and parameters: {'learning_rate': 0.03422318545077307, 'depth': 10, 'subsample': 0.9972065011796857, 'colsample_bylevel': 0.5577311868085701, 'min_data_in_leaf': 100}. Best is trial 11 with value: 3491.3904832966023.\n",
      "[I 2024-02-26 17:53:43,505] Trial 14 finished with value: 6137.818807955221 and parameters: {'learning_rate': 0.001067191621712628, 'depth': 8, 'subsample': 0.8474394307235293, 'colsample_bylevel': 0.4016490981167037, 'min_data_in_leaf': 86}. Best is trial 11 with value: 3491.3904832966023.\n",
      "[I 2024-02-26 17:53:53,044] Trial 15 finished with value: 3871.1076362987365 and parameters: {'learning_rate': 0.055457928622986784, 'depth': 4, 'subsample': 0.8271127377857692, 'colsample_bylevel': 0.2521468779674566, 'min_data_in_leaf': 88}. Best is trial 11 with value: 3491.3904832966023.\n",
      "[I 2024-02-26 17:54:32,556] Trial 16 finished with value: 3801.9287345168627 and parameters: {'learning_rate': 0.013827861256004131, 'depth': 10, 'subsample': 0.9168311351036459, 'colsample_bylevel': 0.6002663852947454, 'min_data_in_leaf': 88}. Best is trial 11 with value: 3491.3904832966023.\n",
      "[I 2024-02-26 17:54:45,162] Trial 17 finished with value: 3787.751215847349 and parameters: {'learning_rate': 0.02081794974640833, 'depth': 7, 'subsample': 0.3104348442888306, 'colsample_bylevel': 0.6759087764900398, 'min_data_in_leaf': 57}. Best is trial 11 with value: 3491.3904832966023.\n",
      "[I 2024-02-26 17:55:12,261] Trial 18 finished with value: 3507.864502652437 and parameters: {'learning_rate': 0.09853320353301233, 'depth': 9, 'subsample': 0.7385946305469033, 'colsample_bylevel': 0.43683335590220795, 'min_data_in_leaf': 4}. Best is trial 11 with value: 3491.3904832966023.\n",
      "[I 2024-02-26 17:55:20,618] Trial 19 finished with value: 3889.5286955812 and parameters: {'learning_rate': 0.05287252643636524, 'depth': 4, 'subsample': 0.6161750593718341, 'colsample_bylevel': 0.2643265533751298, 'min_data_in_leaf': 81}. Best is trial 11 with value: 3491.3904832966023.\n",
      "[I 2024-02-26 17:55:48,984] Trial 20 finished with value: 3727.3147299418124 and parameters: {'learning_rate': 0.021218576830158674, 'depth': 9, 'subsample': 0.9493208451258154, 'colsample_bylevel': 0.4990891291999955, 'min_data_in_leaf': 97}. Best is trial 11 with value: 3491.3904832966023.\n",
      "[I 2024-02-26 17:56:17,579] Trial 21 finished with value: 3530.0202082809446 and parameters: {'learning_rate': 0.0952200331300252, 'depth': 9, 'subsample': 0.7772926527116268, 'colsample_bylevel': 0.42782974311228084, 'min_data_in_leaf': 1}. Best is trial 11 with value: 3491.3904832966023.\n",
      "[I 2024-02-26 17:56:55,494] Trial 22 finished with value: 3601.1122282379242 and parameters: {'learning_rate': 0.050252312751060665, 'depth': 10, 'subsample': 0.8843810041483134, 'colsample_bylevel': 0.472714566104123, 'min_data_in_leaf': 4}. Best is trial 11 with value: 3491.3904832966023.\n",
      "[I 2024-02-26 17:57:24,582] Trial 23 finished with value: 3502.994007353528 and parameters: {'learning_rate': 0.09846187715707964, 'depth': 9, 'subsample': 0.7535216731991895, 'colsample_bylevel': 0.6677755861232275, 'min_data_in_leaf': 17}. Best is trial 11 with value: 3491.3904832966023.\n",
      "[I 2024-02-26 17:57:46,670] Trial 24 finished with value: 3604.448692137403 and parameters: {'learning_rate': 0.062415639601165196, 'depth': 8, 'subsample': 0.6077613494957431, 'colsample_bylevel': 0.7067391687728818, 'min_data_in_leaf': 35}. Best is trial 11 with value: 3491.3904832966023.\n",
      "[I 2024-02-26 17:58:09,165] Trial 25 finished with value: 3649.6364959633606 and parameters: {'learning_rate': 0.042249753583292575, 'depth': 7, 'subsample': 0.9234331384865604, 'colsample_bylevel': 0.6741086714264108, 'min_data_in_leaf': 14}. Best is trial 11 with value: 3491.3904832966023.\n",
      "[I 2024-02-26 17:58:47,748] Trial 26 finished with value: 3535.027399764348 and parameters: {'learning_rate': 0.07538044928518646, 'depth': 10, 'subsample': 0.7802111588259447, 'colsample_bylevel': 0.5639368912214819, 'min_data_in_leaf': 46}. Best is trial 11 with value: 3491.3904832966023.\n",
      "[I 2024-02-26 17:59:11,685] Trial 27 finished with value: 3738.8951130354535 and parameters: {'learning_rate': 0.02216353512720377, 'depth': 9, 'subsample': 0.8040182273125134, 'colsample_bylevel': 0.31753314431323687, 'min_data_in_leaf': 94}. Best is trial 11 with value: 3491.3904832966023.\n",
      "[I 2024-02-26 17:59:28,708] Trial 28 finished with value: 4482.805397470237 and parameters: {'learning_rate': 0.006453880729315244, 'depth': 7, 'subsample': 0.9472214485666197, 'colsample_bylevel': 0.8675148264507007, 'min_data_in_leaf': 77}. Best is trial 11 with value: 3491.3904832966023.\n",
      "[I 2024-02-26 17:59:47,843] Trial 29 finished with value: 3591.78085350385 and parameters: {'learning_rate': 0.07018333267870273, 'depth': 8, 'subsample': 0.5868087380825276, 'colsample_bylevel': 0.7365243133799209, 'min_data_in_leaf': 46}. Best is trial 11 with value: 3491.3904832966023.\n",
      "[I 2024-02-26 18:00:23,832] Trial 30 finished with value: 3622.805921843037 and parameters: {'learning_rate': 0.04567116511461304, 'depth': 10, 'subsample': 0.41611593692856247, 'colsample_bylevel': 0.6490639457535929, 'min_data_in_leaf': 64}. Best is trial 11 with value: 3491.3904832966023.\n",
      "[I 2024-02-26 18:00:49,036] Trial 31 finished with value: 3540.208824350762 and parameters: {'learning_rate': 0.08341790146718654, 'depth': 9, 'subsample': 0.7335030314727419, 'colsample_bylevel': 0.4283164987686307, 'min_data_in_leaf': 10}. Best is trial 11 with value: 3491.3904832966023.\n",
      "[I 2024-02-26 18:01:16,524] Trial 32 finished with value: 3502.025360013163 and parameters: {'learning_rate': 0.09978982407157752, 'depth': 9, 'subsample': 0.88043973989412, 'colsample_bylevel': 0.5183329830004364, 'min_data_in_leaf': 11}. Best is trial 11 with value: 3491.3904832966023.\n",
      "[I 2024-02-26 18:01:38,236] Trial 33 finished with value: 3589.5545535902747 and parameters: {'learning_rate': 0.06878023543100742, 'depth': 8, 'subsample': 0.8752686893303423, 'colsample_bylevel': 0.5299752611849392, 'min_data_in_leaf': 17}. Best is trial 11 with value: 3491.3904832966023.\n",
      "[I 2024-02-26 18:02:08,456] Trial 34 finished with value: 3647.9131320490555 and parameters: {'learning_rate': 0.03944122809509895, 'depth': 9, 'subsample': 0.9899947618526805, 'colsample_bylevel': 0.6245131369643726, 'min_data_in_leaf': 31}. Best is trial 11 with value: 3491.3904832966023.\n",
      "[I 2024-02-26 18:02:48,496] Trial 35 finished with value: 3464.596109040561 and parameters: {'learning_rate': 0.09886907332732021, 'depth': 10, 'subsample': 0.9045876332454507, 'colsample_bylevel': 0.5525983482670428, 'min_data_in_leaf': 10}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:02:58,325] Trial 36 finished with value: 6295.249466206778 and parameters: {'learning_rate': 0.0010594512007658348, 'depth': 7, 'subsample': 0.06261941450026376, 'colsample_bylevel': 0.5650020304763539, 'min_data_in_leaf': 11}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:03:05,650] Trial 37 finished with value: 3900.1155726604416 and parameters: {'learning_rate': 0.09805062282920923, 'depth': 2, 'subsample': 0.8861821991133161, 'colsample_bylevel': 0.8467607080842497, 'min_data_in_leaf': 19}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:03:13,786] Trial 38 finished with value: 3697.752221766929 and parameters: {'learning_rate': 0.061353776787240875, 'depth': 5, 'subsample': 0.2619183337599639, 'colsample_bylevel': 0.7191236599689799, 'min_data_in_leaf': 28}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:03:43,126] Trial 39 finished with value: 3670.4026221718677 and parameters: {'learning_rate': 0.027285960644246838, 'depth': 10, 'subsample': 0.9062308453238367, 'colsample_bylevel': 0.378021216094263, 'min_data_in_leaf': 8}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:04:09,588] Trial 40 finished with value: 3755.029280169235 and parameters: {'learning_rate': 0.015770306773758208, 'depth': 9, 'subsample': 0.8006844770491337, 'colsample_bylevel': 0.9830907363286097, 'min_data_in_leaf': 21}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:04:47,801] Trial 41 finished with value: 3524.450733710968 and parameters: {'learning_rate': 0.07682636037963674, 'depth': 10, 'subsample': 0.9521518131613756, 'colsample_bylevel': 0.47601744957620284, 'min_data_in_leaf': 93}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:05:24,873] Trial 42 finished with value: 3481.5661318606135 and parameters: {'learning_rate': 0.09857674879053854, 'depth': 10, 'subsample': 0.8497084417772798, 'colsample_bylevel': 0.4887357791088517, 'min_data_in_leaf': 15}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:05:52,106] Trial 43 finished with value: 5586.877713530217 and parameters: {'learning_rate': 0.0015234077810261026, 'depth': 9, 'subsample': 0.6972796998377055, 'colsample_bylevel': 0.5426430039630605, 'min_data_in_leaf': 15}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:06:33,744] Trial 44 finished with value: 3471.90082278906 and parameters: {'learning_rate': 0.09782645495322895, 'depth': 10, 'subsample': 0.8376261677964733, 'colsample_bylevel': 0.6206834086603226, 'min_data_in_leaf': 27}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:07:16,617] Trial 45 finished with value: 3564.564367793906 and parameters: {'learning_rate': 0.06371742862210363, 'depth': 10, 'subsample': 0.8492836836661437, 'colsample_bylevel': 0.5980289527410039, 'min_data_in_leaf': 24}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:07:45,974] Trial 46 finished with value: 4333.967763916989 and parameters: {'learning_rate': 0.00660581991666363, 'depth': 10, 'subsample': 0.6636791687547223, 'colsample_bylevel': 0.3488217092252579, 'min_data_in_leaf': 32}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:08:27,806] Trial 47 finished with value: 3607.304827986419 and parameters: {'learning_rate': 0.05016716542410721, 'depth': 10, 'subsample': 0.8389313207825422, 'colsample_bylevel': 0.5169849039905389, 'min_data_in_leaf': 7}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:08:47,680] Trial 48 finished with value: 3574.725806872086 and parameters: {'learning_rate': 0.07934591391287336, 'depth': 8, 'subsample': 0.9162311809456829, 'colsample_bylevel': 0.27944536289305455, 'min_data_in_leaf': 44}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:09:10,262] Trial 49 finished with value: 3684.8622825440566 and parameters: {'learning_rate': 0.03728008678365275, 'depth': 10, 'subsample': 0.8180405856608821, 'colsample_bylevel': 0.17474382960225937, 'min_data_in_leaf': 40}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:09:39,026] Trial 50 finished with value: 3685.3091619640195 and parameters: {'learning_rate': 0.028577040760904084, 'depth': 9, 'subsample': 0.8721638041617591, 'colsample_bylevel': 0.4459472355834286, 'min_data_in_leaf': 13}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:10:08,784] Trial 51 finished with value: 3507.2044905568187 and parameters: {'learning_rate': 0.0999881373102189, 'depth': 9, 'subsample': 0.7678893141537351, 'colsample_bylevel': 0.628529785795622, 'min_data_in_leaf': 19}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:10:50,194] Trial 52 finished with value: 3522.5663148651165 and parameters: {'learning_rate': 0.08465124911510824, 'depth': 10, 'subsample': 0.9596245329225657, 'colsample_bylevel': 0.5705626566562259, 'min_data_in_leaf': 25}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:11:19,419] Trial 53 finished with value: 3589.7149738890644 and parameters: {'learning_rate': 0.059989296226172495, 'depth': 9, 'subsample': 0.7545969564262258, 'colsample_bylevel': 0.7573512223330977, 'min_data_in_leaf': 1}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:12:04,137] Trial 54 finished with value: 3519.1332569814285 and parameters: {'learning_rate': 0.08460621452101706, 'depth': 10, 'subsample': 0.9269089559837543, 'colsample_bylevel': 0.6678198900634447, 'min_data_in_leaf': 7}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:12:24,659] Trial 55 finished with value: 3521.751885562309 and parameters: {'learning_rate': 0.09977963764051075, 'depth': 8, 'subsample': 0.7042678614580515, 'colsample_bylevel': 0.5940546068094044, 'min_data_in_leaf': 57}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:12:51,480] Trial 56 finished with value: 3588.1037390977785 and parameters: {'learning_rate': 0.06962256378521044, 'depth': 9, 'subsample': 0.6465760742690797, 'colsample_bylevel': 0.513163827712082, 'min_data_in_leaf': 27}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:13:22,758] Trial 57 finished with value: 3607.9216029761196 and parameters: {'learning_rate': 0.05109569404412089, 'depth': 10, 'subsample': 0.5593596222336981, 'colsample_bylevel': 0.40122227244576014, 'min_data_in_leaf': 16}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:13:51,673] Trial 58 finished with value: 5181.116691177278 and parameters: {'learning_rate': 0.002210116222707201, 'depth': 9, 'subsample': 0.8565924119740486, 'colsample_bylevel': 0.4617549388477805, 'min_data_in_leaf': 12}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:14:05,423] Trial 59 finished with value: 3630.0882913973464 and parameters: {'learning_rate': 0.08232757211322167, 'depth': 5, 'subsample': 0.9960377693252769, 'colsample_bylevel': 0.8319477595421163, 'min_data_in_leaf': 22}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:14:13,802] Trial 60 finished with value: 3870.915286349372 and parameters: {'learning_rate': 0.05629151694401683, 'depth': 3, 'subsample': 0.8084075862717747, 'colsample_bylevel': 0.49651348221253927, 'min_data_in_leaf': 19}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:14:45,669] Trial 61 finished with value: 3540.7490390656967 and parameters: {'learning_rate': 0.07392999486040858, 'depth': 10, 'subsample': 0.9781002674627863, 'colsample_bylevel': 0.387530243118117, 'min_data_in_leaf': 83}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:15:29,635] Trial 62 finished with value: 3495.874242668095 and parameters: {'learning_rate': 0.08986740678025593, 'depth': 10, 'subsample': 0.9033461051081187, 'colsample_bylevel': 0.7008252584339142, 'min_data_in_leaf': 90}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:16:13,874] Trial 63 finished with value: 3495.7080297966118 and parameters: {'learning_rate': 0.08897386820641053, 'depth': 10, 'subsample': 0.8955585893802376, 'colsample_bylevel': 0.6817164920383052, 'min_data_in_leaf': 89}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:16:59,958] Trial 64 finished with value: 3605.838231692538 and parameters: {'learning_rate': 0.045049442985066884, 'depth': 10, 'subsample': 0.9026298357488919, 'colsample_bylevel': 0.7611852286214954, 'min_data_in_leaf': 92}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:17:44,548] Trial 65 finished with value: 3498.5578151641953 and parameters: {'learning_rate': 0.08805282777291994, 'depth': 10, 'subsample': 0.9400060511204986, 'colsample_bylevel': 0.6909637615652546, 'min_data_in_leaf': 89}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:18:29,622] Trial 66 finished with value: 3538.1496557987557 and parameters: {'learning_rate': 0.06705124427184696, 'depth': 10, 'subsample': 0.9587469672122794, 'colsample_bylevel': 0.6929682438427186, 'min_data_in_leaf': 76}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:19:12,308] Trial 67 finished with value: 3515.9252650054445 and parameters: {'learning_rate': 0.0835784208542745, 'depth': 10, 'subsample': 0.9321799772790411, 'colsample_bylevel': 0.640039471440388, 'min_data_in_leaf': 96}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:19:58,615] Trial 68 finished with value: 3569.68448533384 and parameters: {'learning_rate': 0.054686333880184256, 'depth': 10, 'subsample': 0.8335661247187552, 'colsample_bylevel': 0.8025366875446255, 'min_data_in_leaf': 89}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:20:35,663] Trial 69 finished with value: 3546.555335056647 and parameters: {'learning_rate': 0.07058215954873834, 'depth': 10, 'subsample': 0.477795184123446, 'colsample_bylevel': 0.7267415414334206, 'min_data_in_leaf': 83}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:21:04,006] Trial 70 finished with value: 3522.5293029904637 and parameters: {'learning_rate': 0.08728975671179688, 'depth': 9, 'subsample': 0.9350659011243343, 'colsample_bylevel': 0.5843849565219981, 'min_data_in_leaf': 73}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:21:44,451] Trial 71 finished with value: 3495.5048647739018 and parameters: {'learning_rate': 0.09233378247507194, 'depth': 10, 'subsample': 0.8927211797862105, 'colsample_bylevel': 0.620229643890608, 'min_data_in_leaf': 91}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:22:28,474] Trial 72 finished with value: 3492.253810377098 and parameters: {'learning_rate': 0.09048110682023225, 'depth': 10, 'subsample': 0.8666921629933007, 'colsample_bylevel': 0.7018486574088009, 'min_data_in_leaf': 90}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:23:09,864] Trial 73 finished with value: 3557.4954974280295 and parameters: {'learning_rate': 0.06327361037832588, 'depth': 10, 'subsample': 0.8954658751823266, 'colsample_bylevel': 0.6536254548630148, 'min_data_in_leaf': 98}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:23:37,903] Trial 74 finished with value: 3541.2798226988166 and parameters: {'learning_rate': 0.07572534516025997, 'depth': 9, 'subsample': 0.8696457735051555, 'colsample_bylevel': 0.6203106084971666, 'min_data_in_leaf': 100}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:24:14,752] Trial 75 finished with value: 3519.917096449613 and parameters: {'learning_rate': 0.09118153344925134, 'depth': 10, 'subsample': 0.8307707505532067, 'colsample_bylevel': 0.5372299719872198, 'min_data_in_leaf': 85}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:27:04,554] Trial 76 finished with value: 3581.6711807392144 and parameters: {'learning_rate': 0.05809819189270996, 'depth': 10, 'subsample': 0.9699665387261536, 'colsample_bylevel': 0.7458714266807376, 'min_data_in_leaf': 80}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:27:32,468] Trial 77 finished with value: 3629.7664283910594 and parameters: {'learning_rate': 0.04751183362961193, 'depth': 9, 'subsample': 0.7800585331786817, 'colsample_bylevel': 0.7167137156311895, 'min_data_in_leaf': 91}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:28:12,300] Trial 78 finished with value: 3546.130325981466 and parameters: {'learning_rate': 0.07135366252490678, 'depth': 10, 'subsample': 0.8982106862186207, 'colsample_bylevel': 0.6101135836023036, 'min_data_in_leaf': 96}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:28:41,500] Trial 79 finished with value: 4015.271325466312 and parameters: {'learning_rate': 0.010694585601236338, 'depth': 9, 'subsample': 0.8009809647899385, 'colsample_bylevel': 0.8102287422788736, 'min_data_in_leaf': 87}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:28:55,366] Trial 80 finished with value: 3603.540766829504 and parameters: {'learning_rate': 0.08758370350613069, 'depth': 6, 'subsample': 0.8657566031561709, 'colsample_bylevel': 0.6878898118997532, 'min_data_in_leaf': 95}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:29:42,659] Trial 81 finished with value: 3493.290312720385 and parameters: {'learning_rate': 0.09146348488657897, 'depth': 10, 'subsample': 0.9208724305274292, 'colsample_bylevel': 0.7022980664440752, 'min_data_in_leaf': 89}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:30:33,038] Trial 82 finished with value: 3537.011049538149 and parameters: {'learning_rate': 0.07727095921271757, 'depth': 10, 'subsample': 0.9165304653758727, 'colsample_bylevel': 0.7796179876310073, 'min_data_in_leaf': 91}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:31:20,703] Trial 83 finished with value: 3493.3441912438957 and parameters: {'learning_rate': 0.09160228757042758, 'depth': 10, 'subsample': 0.8484274080103248, 'colsample_bylevel': 0.654881623158893, 'min_data_in_leaf': 68}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:32:04,847] Trial 84 finished with value: 3477.67567653785 and parameters: {'learning_rate': 0.09945169217858416, 'depth': 10, 'subsample': 0.8379418252993693, 'colsample_bylevel': 0.6507387265723185, 'min_data_in_leaf': 67}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:32:41,163] Trial 85 finished with value: 4136.913026314901 and parameters: {'learning_rate': 0.008439054570149481, 'depth': 10, 'subsample': 0.8521137342368386, 'colsample_bylevel': 0.5507336373079386, 'min_data_in_leaf': 59}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:32:46,726] Trial 86 finished with value: 4437.345791937746 and parameters: {'learning_rate': 0.06483383365008574, 'depth': 1, 'subsample': 0.7160278662409698, 'colsample_bylevel': 0.6434832420778807, 'min_data_in_leaf': 64}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:33:13,783] Trial 87 finished with value: 3552.0547232511926 and parameters: {'learning_rate': 0.07649985767714788, 'depth': 9, 'subsample': 0.8198419350347124, 'colsample_bylevel': 0.579166392164838, 'min_data_in_leaf': 78}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:33:41,538] Trial 88 finished with value: 3499.4795916094386 and parameters: {'learning_rate': 0.09915217722066101, 'depth': 9, 'subsample': 0.7447523851725787, 'colsample_bylevel': 0.6530944759722778, 'min_data_in_leaf': 66}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:34:20,257] Trial 89 finished with value: 3580.5153250080107 and parameters: {'learning_rate': 0.05867452111856987, 'depth': 10, 'subsample': 0.7800026789343613, 'colsample_bylevel': 0.606732607163877, 'min_data_in_leaf': 51}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:34:57,378] Trial 90 finished with value: 3521.581562833766 and parameters: {'learning_rate': 0.07697318503465861, 'depth': 10, 'subsample': 0.9727298093106769, 'colsample_bylevel': 0.46378620649808133, 'min_data_in_leaf': 71}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:35:42,930] Trial 91 finished with value: 3500.9675320135757 and parameters: {'learning_rate': 0.09137251834856994, 'depth': 10, 'subsample': 0.8801835110207623, 'colsample_bylevel': 0.6731656964190141, 'min_data_in_leaf': 67}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:36:22,969] Trial 92 finished with value: 4584.04549612398 and parameters: {'learning_rate': 0.0039574768861291645, 'depth': 10, 'subsample': 0.8500482402140432, 'colsample_bylevel': 0.6348387162295258, 'min_data_in_leaf': 4}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:36:55,693] Trial 93 finished with value: 3493.3038512921307 and parameters: {'learning_rate': 0.0917505273771357, 'depth': 10, 'subsample': 0.9482088230852362, 'colsample_bylevel': 0.42205765155126734, 'min_data_in_leaf': 84}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:37:21,363] Trial 94 finished with value: 3563.555261509561 and parameters: {'learning_rate': 0.0691864862491423, 'depth': 9, 'subsample': 0.93928865815635, 'colsample_bylevel': 0.4277147738459651, 'min_data_in_leaf': 82}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:37:45,325] Trial 95 finished with value: 3509.2190591538865 and parameters: {'learning_rate': 0.09887744606705687, 'depth': 10, 'subsample': 0.2967415371142483, 'colsample_bylevel': 0.36281991007208236, 'min_data_in_leaf': 54}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:38:12,401] Trial 96 finished with value: 3537.3785954608534 and parameters: {'learning_rate': 0.08210844485931265, 'depth': 9, 'subsample': 0.9915926090173405, 'colsample_bylevel': 0.44358964543638785, 'min_data_in_leaf': 85}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:38:49,222] Trial 97 finished with value: 3548.794603970336 and parameters: {'learning_rate': 0.06498651360413547, 'depth': 10, 'subsample': 0.9515506418072257, 'colsample_bylevel': 0.48754729044275685, 'min_data_in_leaf': 75}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:39:10,920] Trial 98 finished with value: 3549.75697785543 and parameters: {'learning_rate': 0.09257953546837464, 'depth': 8, 'subsample': 0.9203339239371329, 'colsample_bylevel': 0.5582752298679273, 'min_data_in_leaf': 80}. Best is trial 35 with value: 3464.596109040561.\n",
      "[I 2024-02-26 18:39:21,694] Trial 99 finished with value: 3779.937299415461 and parameters: {'learning_rate': 0.08052933952087188, 'depth': 10, 'subsample': 0.7918753332870292, 'colsample_bylevel': 0.06910706236664216, 'min_data_in_leaf': 98}. Best is trial 35 with value: 3464.596109040561.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CatBoost parameters: {'learning_rate': 0.09886907332732021, 'depth': 10, 'subsample': 0.9045876332454507, 'colsample_bylevel': 0.5525983482670428, 'min_data_in_leaf': 10}\n",
      "Best CatBoost MWIS score: 3464.596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x1de24340bd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MWIS score: 3464.596\n",
      "Coverage: 66.2 %\n"
     ]
    }
   ],
   "source": [
    "# def objective(trial):\n",
    "#     params = {\n",
    "#         \"iterations\": 1000,\n",
    "#         \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "#         \"depth\": trial.suggest_int(\"depth\", 1, 20),\n",
    "#         \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "#         \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1.0),\n",
    "#         \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
    "#     }\n",
    "\n",
    "#     model = CatBoostRegressor(**params, silent=True)\n",
    "#     model.fit(X_train, y_train)\n",
    "#     predictions = model.predict(X_test)\n",
    "#     prediction_intervals = np.quantile(predictions, [alpha / 2, 1 - alpha / 2], axis=0)\n",
    "#     results_df = pd.DataFrame({\n",
    "#         'y_true': y_test.values,\n",
    "#         'lower': prediction_intervals[0],\n",
    "#         'upper': prediction_intervals[1]\n",
    "#     })\n",
    "#     MWIS, coverage = score(results_df[\"y_true\"], results_df[\"lower\"], results_df[\"upper\"], alpha)\n",
    "#     return MWIS\n",
    "\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective, n_trials=100)\n",
    "\n",
    "# best_params_catboost = study.best_params\n",
    "# best_score_catboost = study.best_value\n",
    "\n",
    "# print(\"Best CatBoost parameters:\", best_params_catboost)\n",
    "# print(\"Best CatBoost MWIS score:\", round(best_score_catboost, 3))\n",
    "\n",
    "# # Calculate MWIS score for the best parameters found\n",
    "# model = CatBoostRegressor(**best_params_catboost, silent=True)\n",
    "# model.fit(X_train, y_train)\n",
    "# predictions = model.predict(X_test)\n",
    "# prediction_intervals = np.quantile(predictions, [alpha / 2, 1 - alpha / 2], axis=0)\n",
    "# results_df = pd.DataFrame({\n",
    "#     'y_true': y_test.values,\n",
    "#     'lower': prediction_intervals[0],\n",
    "#     'upper': prediction_intervals[1]\n",
    "# })\n",
    "# MWIS, coverage = score(results_df[\"y_true\"], results_df[\"lower\"], results_df[\"upper\"], alpha)\n",
    "# print(\"MWIS score:\", round(MWIS, 3))\n",
    "# print(\"Coverage:\", round(coverage * 100, 1), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x1de23c574d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MWIS score: 3464.596\n",
      "Coverage: 66.2 %\n"
     ]
    }
   ],
   "source": [
    "# CatBoost w/best parameters from optuna\n",
    "catboost_model = CatBoostRegressor(learning_rate=0.09886907332732021, \n",
    "                                    depth=10, \n",
    "                                    subsample=0.9045876332454507, \n",
    "                                    colsample_bylevel=0.5525983482670428, \n",
    "                                    min_data_in_leaf=10)\n",
    "catboost_model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "predictions = catboost_model.predict(X_test)\n",
    "\n",
    "# Compute prediction intervals\n",
    "prediction_intervals = np.quantile(predictions, [alpha / 2, 1 - alpha / 2], axis=0)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'y_true': y_test.values,\n",
    "    'lower': prediction_intervals[0],\n",
    "    'upper': prediction_intervals[1]\n",
    "})\n",
    "\n",
    "# MWIS score\n",
    "MWIS, coverage = score(results_df[\"y_true\"], results_df[\"lower\"], results_df[\"upper\"], alpha)\n",
    "print(\"MWIS score:\", round(MWIS, 3))\n",
    "print(\"Coverage:\", round(coverage * 100, 1), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
